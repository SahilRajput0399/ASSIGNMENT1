{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e059941-8808-4009-9ab6-899395fb1c6b",
   "metadata": {},
   "source": [
    "Ques1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e7a6e-f137-4989-9761-3b22ad6119f4",
   "metadata": {},
   "source": [
    "Ans. Web scraping refers to the process of extracting data from websites using automated programs or scripts. In other words, it is a technique for extracting data from web pages in an automated manner. The extracted data is then used for various purposes, such as data analysis, research, and machine learning.\n",
    "\n",
    "Here are three areas where web scraping is used to get data:\n",
    "\n",
    "1.E-commerce: Web scraping is commonly used in the e-commerce industry to collect data on product prices, product descriptions, customer reviews, and more. This data can be used to optimize pricing, improve product descriptions, and monitor competitors.\n",
    "\n",
    "2.Social media: Web scraping is also used to collect data from social media platforms such as Twitter, Facebook, and Instagram. This data can be used to analyze social media trends, track sentiment, and monitor social media campaigns.\n",
    "\n",
    "3.Job boards: Web scraping is used to collect job postings from job boards. This data can be used to analyze job trends, identify skill requirements, and track hiring pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459dfc4-3074-4881-b074-578753650163",
   "metadata": {},
   "source": [
    "Ques2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad691f6-75b9-4e54-9bf0-38564aa55e75",
   "metadata": {},
   "source": [
    "Ans. There are several methods for web scraping, depending on the specific requirements of the project. Here are some of the most common methods used for web scraping:\n",
    "\n",
    "1.Manual scraping: This is the most basic method of web scraping, where data is manually copied and pasted from web pages into a spreadsheet or text editor. It is time-consuming and not scalable, but it may be useful for small projects with limited data.\n",
    "\n",
    "2.Web scraping software: There are several web scraping software tools available that automate the process of web scraping. These tools can extract data from web pages and save it in a structured format such as CSV, JSON, or XML.\n",
    "\n",
    "3.APIs: Some websites provide APIs (Application Programming Interfaces) that allow users to access data in a structured format. APIs are a reliable and scalable way to extract data from websites, but they may require authentication and often have usage limits.\n",
    "\n",
    "4.Parsing HTML: HTML parsing involves analyzing the HTML structure of a web page to extract data. This can be done using programming languages like Python or Ruby, and libraries like Beautiful Soup and Nokogiri.\n",
    "\n",
    "5.Headless browsing: Headless browsing involves using a browser to scrape data from a website, without actually rendering the page. This method can be useful for scraping dynamic websites that use JavaScript, but it requires more technical expertise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3813b19-3608-4777-b709-ebc32bc7fa07",
   "metadata": {},
   "source": [
    "Ques3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ca930-ef92-41de-a1a7-b62c0058012e",
   "metadata": {},
   "source": [
    "Ans. Beautiful Soup is a Python library used for web scraping purposes. It provides a set of tools for parsing HTML and XML documents, extracting data, navigating the parsed tree, and manipulating the document structure. Beautiful Soup is widely used by web developers, data scientists, and researchers to extract data from websites.\n",
    "\n",
    "The main reasons for using Beautiful Soup for web scraping are:\n",
    "\n",
    "1.Parsing HTML and XML documents: Beautiful Soup can parse both HTML and XML documents, making it a versatile tool for web scraping.\n",
    "\n",
    "2.Extraction of data: Beautiful Soup provides a set of functions that allow developers to extract data from web pages based on the page structure, element attributes, and other criteria.\n",
    "\n",
    "3.Navigation: Beautiful Soup provides a navigable tree-like representation of the HTML or XML document, allowing developers to easily navigate through the document st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ff793-65b9-4d55-9417-61b6dd462dac",
   "metadata": {},
   "source": [
    "Ques4.  Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b39520-3737-4935-a7b4-5b261202a3c2",
   "metadata": {},
   "source": [
    "Ans. Flask is a lightweight web framework for Python that is commonly used for building web applications and APIs. In a web scraping project, Flask can be used for several reasons:\n",
    "\n",
    "1.Building a web interface: Flask can be used to create a simple web interface for the web scraping project, allowing users to enter URLs or search terms, and displaying the results of the web scraping.\n",
    "\n",
    "2.Running a web server: Flask can be used to run a web server that serves the web scraping application, making it accessible to users over the internet.\n",
    "\n",
    "3.Handling HTTP requests: Flask provides tools for handling HTTP requests, such as GET and POST requests, which are used in web scraping to retrieve data from web pages.\n",
    "\n",
    "4.Managing session data: Flask can manage session data, allowing users to save and retrieve information between requests. This can be useful for web scraping projects where users need to store data between different scraping sessions.\n",
    "\n",
    "5.Integration with other Python libraries: Flask can be easily integrated with other Python libraries, including web scraping libraries like Beautiful Soup and Requests, making i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc4e6f-0497-4f8c-af05-cc62e3789b9c",
   "metadata": {},
   "source": [
    "Ques5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de72d5c-b8ea-447d-b462-d313de16211b",
   "metadata": {},
   "source": [
    "Ans. 1. AWS Elastic Beanstalk- AWS Elastic Beanstalk is an AWS managed service for web applications. Elastic beanstalk is a pre-configured EC2 server that can directly take up your application code and environment configurations and use it to automatically provision and deploy the required resources within AWS to run the web application.\n",
    "     2. Code Pipeline - AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
